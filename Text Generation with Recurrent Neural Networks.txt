import tensorflow as tf
from tensorflow.keras.layers import LSTM, Dense
import numpy as np

text = "This is an example text for training a language model."
chars = sorted(set(text))
char_to_idx = {char: idx for idx, char in enumerate(chars)}
idx_to_char = {idx: char for char, idx in char_to_idx.items()}
max_length = 50
sequences = []
next_chars = []

for i in range(len(text) - max_length):
    sequences.append(text[i:i+max_length])
    next_chars.append(text[i+max_length])

X = np.zeros((len(sequences), max_length, len(chars)), dtype=np.bool)
y = np.zeros((len(sequences), len(chars)), dtype=np.bool)

for i, sequence in enumerate(sequences):
    for t, char in enumerate(sequence):
        X[i, t, char_to_idx[char]] = 1
    y[i, char_to_idx[next_chars[i]]] = 1

model = tf.keras.Sequential([
    LSTM(128, input_shape=(max_length, len(chars))),
    Dense(len(chars), activation='softmax')
])
model.compile(loss='categorical_crossentropy', optimizer='adam')

model.fit(X, y, epochs=100, batch_size=128)
